{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["9yvf7WUVOWyN","8xondgGJ_nzX","YwqOMoJpuoTk"],"authorship_tag":"ABX9TyMaG+wxceEaJyo8XtK+vAbj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9yvf7WUVOWyN"},"source":["# **Regresion Lineal**"]},{"cell_type":"markdown","metadata":{"id":"04iPseTDpWuB"},"source":["Webpage de Scikit-Learn [Aquí](https://scikit-learn.org/stable/index.html) \\\\\n","Documentacion de la regresión lineal [Aquí](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linear%20regression#sklearn.linear_model.LinearRegression)"]},{"cell_type":"code","metadata":{"id":"C0lczOZ8DPAI"},"source":["import numpy as np # Librería mateamtica\n","import matplotlib.pyplot as plt # plots\n","from sklearn.linear_model import LinearRegression # scikit-learn: libreria de IA para python"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hld2rrv3EMk5"},"source":["def f(x) : # Recrear el comportamiento de una funcion lineal\n","  y = (0.0918 * x) + 1.2859 + 0.1*np.random.randn (x.shape[0]) # Comportamiento lineal (w*x + b + ruido)\n","  return y \n","\n","# Crear datos de entrenamiento. \n","x = np.arange (0, 10, 0.25); print (x.shape)\n","# Generar etiquetas para cada x \n","y = f(x); print (y.shape)\n","\n","# Diagrama de dispersion\n","plt.scatter(x, y, color = 'blue')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZyR9yfT-GvIo"},"source":["# Instancia de la regresion lineal\n","linear_regression = LinearRegression()\n","\n","# Entrenar el modelo de regresion lineal\n","linear_regression.fit(x.reshape(-1, 1), y) # (#muestras, #caracteristicas)\n","\n","# Imprimir los valores estimados para compararlos respecto a los originales\n","print (\"w = \" + str(linear_regression.coef_) + \", b = \" + str(linear_regression.intercept_))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zm0o7o648Sqb"},"source":["# Nueva muestra. Imprime el valor correspondiente de y \n","new_sample = np.array([5])\n","print (f(new_sample))\n","\n","# Predecir la nueva muestra. Imprimir la prediccion\n","prediction = linear_regression.predict(new_sample.reshape(-1, 1))\n","print (prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R54tUMNw9nQ2"},"source":["# Predecir todos los valores de x\n","predictions = linear_regression.predict(x.reshape(-1, 1))\n","\n","# Dibuja los valores del las muestras (azul) y de prediccion (rojo)\n","_, ax = plt.subplots (figsize=(8,5))\n","ax.scatter(x, y, color = 'blue')\n","ax.plot (x, predictions, color = 'red')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8xondgGJ_nzX"},"source":["# **Regresion Logistica**"]},{"cell_type":"markdown","metadata":{"id":"edL0-1Z5pHpD"},"source":["Descripción de iris dataset [Aquí](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris) \\\\\n","Documentacion de la regresión logistica [Aquí](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regression#sklearn.linear_model.LogisticRegression)"]},{"cell_type":"code","metadata":{"id":"01C1fQOy_uzI"},"source":["import numpy as np \n","import matplotlib.pyplot as plt\n","from sklearn.linear_model import LogisticRegression # Regresion logistica\n","from sklearn.datasets import load_iris # Iris dataset "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HJGIj4F6B5PA"},"source":["iris = load_iris() # Cargar la base de datos iris\n","x = iris.data[:, 0:2] # Caracteristicas. Seleccionamos 2\n","y = iris.target # Etiquetas\n","\n","# Imprimir formas\n","print (x.shape, y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3C_5YQJRCm2V"},"source":["# Instancia de la regresion logistica\n","logistic_regression = LogisticRegression()\n","\n","# Entrenar el modelo de regresion logistica\n","logistic_regression.fit (x, y) #(#muestras, #caracteristicas)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qNrNLfqbDIQq"},"source":["# Valores minimos y maximos para crear el grid de las fronteras de decision\n","x_min, x_max = x[:, 0].min(), x[:, 0].max()\n","y_min, y_max = x[:, 1].min(), x[:, 1].max()\n","\n","# Crear el grid de las fronteras de decision\n","x_grid, y_grid = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n","\n","# Predecir los valores del grid\n","predictions = logistic_regression.predict(np.c_[x_grid.ravel(), y_grid.ravel()])\n","print (predictions.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fNXGUbNHFPMI"},"source":["# Encajar las predicciones al tamaño del grid\n","predictions = predictions.reshape(x_grid.shape)\n","\n","# Dibujar el grid y las fronteras de decision\n","_, ax = plt.subplots (figsize=(8,5))\n","ax.pcolormesh(x_grid, y_grid, predictions, cmap = plt.cm.Paired)\n","\n","# Imprimir las muestras con el scatter\n","ax.scatter (x[:, 0], x[:, 1],  c=y, edgecolors='k', cmap=plt.cm.Paired)\n","ax.set_xlim(x_grid.min(), x_grid.max())\n","ax.set_ylim(y_grid.min(), y_grid.max())\n","ax.set_xticks(())\n","ax.set_yticks(())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YwqOMoJpuoTk"},"source":["# **K vecinos cercanos (kNN)**"]},{"cell_type":"markdown","metadata":{"id":"uO3bdE2CwpKf"},"source":["Documentacion de kNN [Aquí](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html?highlight=kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier)"]},{"cell_type":"code","metadata":{"id":"KYGjWF-euoT0"},"source":["import numpy as np \n","import matplotlib.pyplot as plt\n","#from sklearn.linear_model import LogisticRegression # Regresion logistica (omitido)\n","from sklearn.neighbors import KNeighborsClassifier as kNN # kNN\n","from sklearn.datasets import load_iris # Iris dataset "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oMPSzONJuoUQ"},"source":["iris = load_iris() # Cargar la base de datos iris\n","x = iris.data[:, 0:2] # Caracteristicas. Seleccionamos 2\n","y = iris.target # Etiquetas\n","\n","# Imprimir formas\n","print (x.shape, y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jzpqaC2hu-xk"},"source":["# Asi se entrenaba la regresion logistica\n","#logistic_regression = LogisticRegression()\n","#logistic_regression.fit (x, y)\n","\n","# Asi se entrena el kNN\n","neighbors = 3 # Parametro critico: numero de vecinos\n","knn = kNN(neighbors)\n","knn.fit (x, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z3L-by2BveYl"},"source":["# Valores minimos y maximos para crear el grid de las fronteras de decision\n","x_min, x_max = x[:, 0].min(), x[:, 0].max()\n","y_min, y_max = x[:, 1].min(), x[:, 1].max()\n","\n","# Crear el grid de las fronteras de decision\n","x_grid, y_grid = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n","\n","# Predecir los valores del grid\n","predictions = knn.predict(np.c_[x_grid.ravel(), y_grid.ravel()])\n","print (predictions.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_WG47POIveY0"},"source":["# Encajar las predicciones al tamaño del grid\n","predictions = predictions.reshape(x_grid.shape)\n","\n","# Dibujar el grid y las fronteras de decision\n","_, ax = plt.subplots (figsize=(8,5))\n","ax.pcolormesh(x_grid, y_grid, predictions, cmap = plt.cm.Paired)\n","\n","# Imprimir las muestras con el scatter\n","ax.scatter (x[:, 0], x[:, 1],  c=y, edgecolors='k', cmap=plt.cm.Paired)\n","ax.set_xlim(x_grid.min(), x_grid.max())\n","ax.set_ylim(y_grid.min(), y_grid.max())\n","ax.set_xticks(())\n","ax.set_yticks(())"],"execution_count":null,"outputs":[]}]}